# -*- coding: utf-8 -*-
"""Project_DL

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y2XRbzSsuSTFUM8hywcwjRYjDGasoFyX

# Fetching data from database
"""

# Fetching data from Google Sheets
import gspread
import pandas as pd
from google.auth import default
from google.colab import auth
auth.authenticate_user()
creds, _ = default()
gc = gspread.authorize(creds)
spreadsheet = gc.open_by_key('1EH95aGJZQTrfI6G-5Hx73yCgkbQTKzk1QX_YJ9E7Dlk')
worksheet = spreadsheet.get_worksheet(0)
df = pd.DataFrame(worksheet.get_all_records())
# Prints first 6 tuples
print(df[:6])

"""# Necessary Imports"""

import tensorflow as tf
import matplotlib
import matplotlib.pyplot as plt
import keras
import numpy as np

"""# Determining current GPU"""

# Test for GPU and determine what GPU we have
import platform
import subprocess
gpu_devices = tf.config.list_physical_devices('GPU')

gpu_name = tf.test.gpu_device_name()
if gpu_name != '':
    print('TF-GPU-devname:',tf.test.gpu_device_name())
    sys_details = tf.sysconfig.get_build_info()
    physical_devices = tf.config.list_physical_devices('GPU')
    print("Num GPUs:", len(physical_devices))
    if platform.system() == "Darwin":
        print('GPU on Mac!')
    else:
        cuda_version = sys_details["cuda_version"]
        print('TF-cuda version:',cuda_version)
        if len(physical_devices)>0:
            process = subprocess.Popen(['nvidia-smi','-L'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            print(process.communicate())
        # If possible to run code with 16 bits float instead of 32 bits float, this code activates such functionality:
        if gpu_devices:
            details = tf.config.experimental.get_device_details(gpu_devices[0])
            compute_capability=details.get('compute_capability')
            print("Compute capability:",compute_capability)
            if compute_capability[0]>6:
                print("Turning on mixed_float16")
                policy = keras.mixed_precision.Policy('mixed_float16')
                keras.mixed_precision.set_global_policy(policy)
else:
    print('TF-device CPU')

"""# Exploring the data"""

print("Amount of rows in dataset:", df.shape[0])
print("Amount of attributes in dataset:", df.shape[1])

df.head()

"""# Exploring a few attributes evolution over time"""

print(df.columns)
df['date'] = pd.to_datetime(df['date'], dayfirst=True, format='mixed')
df = df.set_index('date')

plot_cols = ['temperature', 'humidity']
plot_features = df[plot_cols]
_ = plot_features.plot(subplots=True)

"""# Inspect and cleanup of dataset"""

# Remove irrelevant id attribute
df = df.drop(columns=['id'])

df.describe().transpose()

"""**The data looks clean, no outliers ðŸ™‚**

# When measuring the data I noticed that the RPI Pico stopped measuring at two points of time due to exceeded memory.

# This is why we need to find the gaps in the dataset where no measures were made every 30-35 seconds. (I chose to filter through when no measures were made in 90 seconds instead of 30-35 because sometimes the data post took about 1 minute due to slow routing)
"""

df = df.sort_index()

gaps = pd.DataFrame({
  "before": df.index.to_series().shift(1),
  "after": df.index,
  "gap": df.index.to_series().diff(),
  "row_ix": range(len(df))
})

# Threshold for minimum gap to be measured
threshold = pd.Timedelta(seconds=90)

# Defining missed measures where the time inbetween two measures are greater than 90 seconds
gaps = gaps[gaps["gap"] > threshold]

display(gaps)

"""**We found three larger gaps in the dataset**

**Gap 1: 5 minutes**

**Gap 2: 5 hours**

**Gap 3: 9.5 hours**

# Adding the missing values

**The most recent values measured will be applied for all missed measurments for the respective gap**

**The three indexes where the gaps are in the dataset**
"""

indexOfGaps = gaps['row_ix'].tolist()

print(indexOfGaps)

"""**The RPI Pico is programmed to measure every 30 seconds, but sending data to google sheets adds a few seconds, irregurlary.**

**In order to add the correct amount missing data, I need to find the average time in between measurements.**
"""

# Filtering out the larger gaps from the dataset.
time_diff = df.index.to_series().diff()

valid_measurements = time_diff[time_diff <= threshold]

print(valid_measurements)
print()

# Calculating the average value of each time difference
avg_valid_measurements = valid_measurements.dt.total_seconds().mean()

print(f'Average time between measurements {avg_valid_measurements:.2f}')

"""# Let us explore about how many measures were missed.

**Gap 1: (5 * 60) / 35**

**Gap 2: (5 * 60 * 60) / 35**

**Gap 3: (9.5 * 60 * 60) / 35**

**Gap 1 resulted in 9 missed measures.**

**Gap 2 resulted in 514 missed measures.**

**Gap 3 resulted in 977 missed measures.**

**Notice that when I found the three gaps I disregarded smaller gaps, shorter than 90 seconds.**

**Below all of these smaller gaps will be filled as well as the larger ones.**
"""

df_35s = df.resample("35s").mean()
df_filled = df_35s.ffill()

print(df)
print(df_filled)

"""**The original dataset consists of 14 976 rows.**

**The filled dataset consists of 16 456 rows**

**The dataset increased of 16456 - 14976 = 1480 rows**

# We want to predict 1 hour into the future, so we divide the dataset into 1 hour steps
"""

df_1h = df.resample("1h").mean()
df_1h = df_1h.dropna() # Remove all NaN tuples
print("Amount of rows with 1 hour windows:", len(df_1h))

"""# Normalize the data"""

# Split the data into datasets
DataSplitRatios = (0.7, 0.2, 0.1)
n = len(df_1h)
split1ix = int(n*DataSplitRatios[0])
split2ix = int(n*(DataSplitRatios[0] + DataSplitRatios[1]))
print(split1ix, split2ix, n)

"""It is important to scale features before training a neural network. Normalization is a common way of doing this scaling. Subtract the mean and divide by the standard deviation of each feature. Note that the mean and standard deviation should only be computed using the training data so that the models have no access to the values in the validation and test sets.

The data is normalized so that the data is in the same distribution which makes the models to be able to learn easier (Tomas NordstrÃ¶m, 2025-05-08).
"""

train_mean = df_1h[0:split1ix].mean()
train_std = df_1h[0:split1ix].std()
dfnorm = (df_1h - train_mean) / train_std

"""# Exploring distribution of normalized features"""

import seaborn as sns

df_std = dfnorm.melt(var_name='Column', value_name='Normalized')
plt.figure(figsize=(12, 6))
ax = sns.violinplot(x='Column', y='Normalized', data=df_std)
_ = ax.set_xticklabels(df_1h.keys(), rotation=45)

"""# Prepare our three datasets"""

def get_label_columns_indices(dataframe, label_columns=None):
    """
    Returns a dictionary mapping column names to their indices in the given DataFrame.
    Parameters:
        dataframe : pandas.DataFrame
            The DataFrame from which to extract column indices.
        label_columns : list of str, optional
            A list of column names to retrieve indices for. If None, all columns will be included.
    Returns:
        A dictionary where keys are column names and values are their corresponding indices.
    """
    if label_columns is None:
        # Return indices for all columns
        label_columns_indices = {name: i for i, name in enumerate(dataframe.columns)}
    else:
        # Return indices only for the specified label columns
        label_columns_indices = {name: dataframe.columns.get_loc(name) for name in label_columns}
    return label_columns_indices

# Test get_label_columns_indices
lcol= None
lci = get_label_columns_indices(dfnorm,lcol)
print(lci)
lcol= lcol= ['temperature']
lci = get_label_columns_indices(dfnorm,lcol)
print(lci)

# Define a windowing function that converts a dataframe into a TF dataset
# Had to jump to some hoops for this as keras.utils.timeseries_dataset_from_array do not support label_width>1
# https://github.com/keras-team/tf-keras/issues/7
def datasetgen(dataframe, input_width=128, label_width=1, shift=1, batch_size=128,
  label_columns=None, start_index=None, end_index=None, shuffle=False):
  """
  Generate timeseries dataset from the given dataframe containing a data sequence.

  Parameters:
  - dataframe: The source time sequence dataframe.
  - input_width: Number of time steps in each input sequence.
  - label_width: Number of time steps in each label sequence.
  - shift: How many steps to shift the end of the input to get the label.
  - batch_size: Size of batches to generate.
  - label_columns: List of column names to extract as labels. If None, all columns are used.
  - start_index: Start index from the dataframe to consider data. Default is the start of the dataframe.
  - end_index: End index from the dataframe to consider data. Default is the end of the dataframe.
  - shuffle: Whether to shuffle the generated batches. Note: shuffling won't work in the current implementation.

  Returns:
  - A TensorFlow Dataset containing input and label sequences.
  """

  # If end index or start index is not given, assign them to the end or start of the dataframe respectively.
  if end_index is None:
      end_index = len(dataframe) + input_width - 1
  if start_index is None:
      start_index = 0

  # Generate a input timeseries dataset from the dataframe using keras.utils.timeseries_dataset_from_array
  input_ds = keras.utils.timeseries_dataset_from_array(
                  dataframe, targets=None, sequence_length=input_width,
                  sequence_stride=1, sampling_rate=1, batch_size=batch_size, shuffle=shuffle,
                  start_index=start_index, end_index=(end_index-(input_width+shift)))

  # Fetch the indices of the label columns from the dataframe.
  label_columns_indices = get_label_columns_indices(dataframe,label_columns) # get the selected columns
  targetsdf = dataframe[list(label_columns_indices)] # Note that we only use names and not the indices

  # Generate a timeseries dataset of label sequences from the dataframe.
  # Here we assume that label_width should be less than or equal to shift.
  target_ds = keras.utils.timeseries_dataset_from_array(
                  targetsdf, targets=None, sequence_length=label_width,
                  sequence_stride=1, sampling_rate=1, batch_size=batch_size, shuffle=shuffle,
                  start_index=(start_index+(input_width+shift-label_width)),
                  end_index=end_index-input_width)

  # Combine input and target datasets to form a single dataset.
  train_ds = tf.data.Dataset.zip(input_ds,target_ds)

  return train_ds

# Split targets

def split_targets(inputs, targets):
    targets = tf.squeeze(targets, axis=1)  # (batch, 4)
    return inputs, {
        "temperature": targets[:, 0],
        "humidity":  targets[:, 1],
        "eco2": targets[:, 2],
        "tvoc": targets[:, 3],
    }

# Now create the used datasets

input_width=12
shift=1           # How many steps to target
label_width=1     # Target sequence length
lcol=['temperature', 'humidity', 'eco2', 'tvoc'] # Target parameter(s)
train_ds = datasetgen(dfnorm, input_width=input_width, label_width=label_width, shift=shift,
              label_columns=lcol, start_index=0, end_index=split1ix)
val_ds = datasetgen(dfnorm, input_width=input_width, label_width=label_width, shift=shift,
              label_columns=lcol, start_index=split1ix, end_index=split2ix)
test_ds = datasetgen(dfnorm, input_width=input_width, label_width=label_width, shift=shift,
              label_columns=lcol, start_index=split2ix, end_index=None)

train_ds = train_ds.map(split_targets)
val_ds   = val_ds.map(split_targets)
test_ds  = test_ds.map(split_targets)

# Establish test targets (to show how to unroll dataset)
# Discussed with ChatGPT how to transform target establishing from one target to 4.

test_targets = {
    "temperature": [],
    "humidity": [],
    "eco2": [],
    "tvoc": []
}
for inputs, targets in test_ds:
  for x in test_targets:
    test_targets[x].append(targets[x])

for x in test_targets:
  test_targets[x] = tf.concat(test_targets[x], axis=0)

# Get a batch and look at the shapes for one of the datasets
eval_ds = test_ds

for inputs, targets in eval_ds.take(1):
  for key, value in targets.items():
    print(key, value.shape)

"""# Finally the datasets are ready for training

**Exploring loss function**

Defining method for compiling and fitting data
"""

# For reference when compiling a multile output LSTM: https://keras.io/guides/functional_api/

import time

def compile_and_fit(model, train_ds, val_ds, patience=5):
  MAX_EPOCHS = 30
  early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',
                                                    patience=patience,
                                                    mode='min',
                                                    restore_best_weights = True)

  model.compile(optimizer=tf.optimizers.Adam(),
                loss={
                    "temperature": "mse",
                    "humidity": "mse",
                    "eco2": "mse",
                    "tvoc": "mse"
                },
                loss_weights={
                  "temperature": 1.0,
                  "humidity": 1.0,
                  "eco2": 0.5,
                  "tvoc": 0.3
                },
                metrics={
                    "temperature": "mae",
                    "humidity": "mae",
                    "eco2": "mae",
                    "tvoc": "mae"
                }
              )

  start = time.time()
  history = model.fit(train_ds, epochs=MAX_EPOCHS,
                      validation_data=val_ds,
                      callbacks=[early_stopping])
  end = time.time()
  print(f'Time to run: {end - start:.1f}s')

  return history,model

"""# Creating a model"""

# Define a LSTM-model with multiple outputs
# For reference when creating a multile output LSTM: https://keras.io/guides/functional_api/

num_input_features = dfnorm.shape[1]

inputs = keras.Input(shape=(input_width, num_input_features))
lstm_layer = keras.layers.LSTM(64, return_sequences=False)(inputs)

temp = keras.layers.Dense(1, name="temperature")(lstm_layer)
hum = keras.layers.Dense(1, name="humidity")(lstm_layer)
eco2 = keras.layers.Dense(1, name="eco2")(lstm_layer)
tvoc = keras.layers.Dense(1, name="tvoc", activation="relu")(lstm_layer) # Realized i predicted negative tvoc values, which is physically impossible. References: https://www.reddit.com/r/learnmachinelearning/comments/eisotm/what_is_the_best_way_to_deal_with_negative/ & https://keras.io/api/layers/core_layers/dense/

lstm_model = keras.Model(
    inputs = inputs,
    outputs = [temp, hum, eco2, tvoc]
)

"""**Compile and train model**"""

history_lstm_model, lstm_model=compile_and_fit(lstm_model, train_ds, val_ds)

"""**Evaluate model**"""

results = lstm_model.evaluate(test_ds, verbose=0, return_dict=True)

for key, value in results.items():
  print(f"{key}, {value:.4f}\n")

"""# Converting the normalized evaluated units to real units"""

# Discussed with ChatGPT how to convert normalized units to real

for key, value in results.items():
    if key.endswith("_mae"):
        var = key.replace("_mae", "")
        mae_real = value * train_std[var]
        print(f"{var}: MAE: {mae_real:.2f} (real units)\n")

"""# Example plot of predictions"""

# Define a plot function to show how well it is predicting
# Transformed show_plot method from Laboration 3 in discussion with ChatGPT

def show_plot(history, true_future, model_prediction, title):

    time_steps = range(-len(history), 0)

    plt.figure(figsize=(8,4))
    plt.plot(time_steps, history, '.-', label='History')
    plt.plot(1, true_future, 'rx', markersize=6, label='True Future')
    plt.plot(1, model_prediction, 'go', markersize=6, label='Model Prediction')

    plt.legend()
    plt.title(title)
    plt.ylabel("Normalized value")
    plt.xlabel("Time-Step")
    plt.grid(True)
    plt.show()

# @title
for x, y in val_ds.take(3):
  predictions = lstm_model.predict(x)
  show_plot(
        x[0, :, 0].numpy(),              # history (time_steps,)
        y["temperature"][0].numpy(),     # true future
        predictions[0][0][0],            # model prediction
        "Temperature"
        )

# @title
for x, y in val_ds.take(3):
  predictions = lstm_model.predict(x)
  show_plot(
        x[0, :, 0].numpy(),              # history (time_steps,)
        y["humidity"][0].numpy(),        # true future
        predictions[0][0][0],            # model prediction
        "humidity"
        )

# @title
for x, y in val_ds.take(3):
  predictions = lstm_model.predict(x)
  show_plot(
        x[0, :, 0].numpy(),              # history (time_steps,)
        y["eco2"][0].numpy(),            # true future
        predictions[0][0][0],            # model prediction
        "eco2"
        )

# @title
for x, y in val_ds.take(3):
  predictions = lstm_model.predict(x)
  show_plot(
        x[0, :, 0].numpy(),              # history (time_steps,)
        y["tvoc"][0].numpy(),            # true future
        predictions[0][0][0],            # model prediction
        "tvoc"
        )

"""# Plot some unnormalized results"""

# Fetch true temperatures

y_true_temp = []

for x, y in test_ds:
  y_true_temp.append(y['temperature'])

y_true_temp = tf.concat(y_true_temp, axis=0).numpy()

# Perform some predictions

predictions = lstm_model.predict(test_ds)
y_predicted_temp = predictions[0].squeeze() # Predicted temperature output

# Dynamically written unnorm method
# Returns unnormalized values

def unnorm(y_true, y_pred, attribute):
  y_true_attr = (
      y_true* train_std[attribute]
      + train_mean[attribute]
  )

  y_pred_attr = (
      y_pred * train_std[attribute]
      + train_mean[attribute]
  )
  return y_true_attr, y_pred_attr

# Call unnorm method with temperature attribute

y_true_temp_unnormalized, y_pred_temp_unnormalized = unnorm(
    y_true_temp,
    y_predicted_temp,
    "temperature"
)

plt.figure(figsize=(12,6))
plt.plot(y_true_temp_unnormalized, label="True temperature", color="green", alpha=1)
plt.plot(y_pred_temp_unnormalized, label="Predicted temperature", color="red", alpha=1)
plt.ylabel("Temperature (Â°C)")
plt.xlabel("Time step (1 hour)")
plt.legend()
plt.grid(True)
plt.show()

# Call unnorm method with eco2 attribute

y_true_temp_unnormalized, y_pred_temp_unnormalized = unnorm(
    y_true_temp,
    y_predicted_temp,
    "eco2"
)

plt.figure(figsize=(12,6))
plt.plot(y_true_temp_unnormalized, label="True eco2", color="green", alpha=1)
plt.plot(y_pred_temp_unnormalized, label="Predicted eco2", color="red", alpha=1)
plt.ylabel("eco2")
plt.xlabel("Time step (1 hour)")
plt.legend()
plt.grid(True)
plt.show()

"""# Forecasting several time steps (hours) ahead
**Reference to all code blocks below: GÃ©ron, A. ss. 505-511**

**Forecasting several time steps ahead**
"""

# One step is 1 hour

def recursive_func(model, start_window, steps):
  predictions = []
  window = start_window.numpy().copy()

  for step_ahead in range(steps):
    predictions_output = model.predict(window)
    predictions_output = np.concatenate(predictions_output, axis = 1) # Convert list to array
    predictions.append(predictions_output[0])

    # Push window one timestep ahead
    window = np.concatenate([window[:, 1:, :], predictions_output[:, None, :]], axis=1)

  return np.array(predictions)

"""**Perform predictions**"""

# Fetch from test dataset
steps=12 # Feel free to alter this variable and rerun from this cell and below to perform predictions from 1-14 steps

for x, y in test_ds.take(1):
  start_window = x[0:1]
  break
predictions = recursive_func(lstm_model, start_window, steps)

"""**We need to fetch the true future in order to compare our predicted values**"""

start_index = split2ix # The beginning of the test data which we already declared in the beginning of the file

true_future = df_1h.iloc[start_index + steps][["temperature", "humidity", "eco2", "tvoc"]].values # Fetch and store true values from where test data starts and 12 hours (steps) ahead

pred_real = predictions * train_std.values + train_mean.values
last_pred = pred_real[-1]

print(
      steps, "hours ahead:\n"
      "Temperature:", f"{last_pred[0]:.4f}\n",
      "Humidity:", f"{last_pred[1]:.4f}\n",
      "eCO2:", f"{last_pred[2]:.4f}\n",
      "TVOC:", f"{last_pred[3]:.4f}\n"
    )

print(
    "True future values:\n",
    "Temperature:", f"{true_future[0]:.4f}\n",
      "Humidity:", f"{true_future[1]:.4f}\n",
      "eCO2:", f"{true_future[2]:.4f}\n",
      "TVOC:", f"{true_future[3]:.4f}\n"
)